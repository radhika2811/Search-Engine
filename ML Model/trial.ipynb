{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cc01d008",
   "metadata": {},
   "outputs": [],
   "source": [
    "#All Necessary Imports\n",
    "import os\n",
    "import gc  # Garbage Collector for memory management\n",
    "import PyPDF2\n",
    "import numpy as np\n",
    "import faiss  \n",
    "from sentence_transformers import SentenceTransformer\n",
    "from transformers import pipeline\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "60072ad4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to Load and Chunk the Document \n",
    "def load_and_chunk_text(file_path, chunk_size=500, chunk_overlap=50):\n",
    "    \"\"\"\n",
    "    Loads text from a PDF and splits it into meaningful, overlapping chunks.\n",
    "    \"\"\"\n",
    "    if not os.path.exists(file_path):\n",
    "        print(f\"Error: The file '{file_path}' was not found.\")\n",
    "        return None\n",
    "    text = \"\"\n",
    "    try:\n",
    "        with open(file_path, \"rb\") as f:\n",
    "            reader = PyPDF2.PdfReader(f)\n",
    "            for page in reader.pages:\n",
    "                page_text = page.extract_text()\n",
    "                if page_text:\n",
    "                    text += page_text + \"\\n\"\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred while reading the PDF: {e}\")\n",
    "        return None\n",
    "    if not text.strip():\n",
    "        print(f\"Warning: No text could be extracted from '{file_path}'.\")\n",
    "        return []\n",
    "    text_splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=chunk_size, chunk_overlap=chunk_overlap, length_function=len\n",
    "    )\n",
    "    chunks = text_splitter.split_text(text)\n",
    "    print(f\"Successfully loaded and created {len(chunks)} chunks from '{file_path}'.\")\n",
    "    return chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fdc20f78",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to Create a FAISS Index\n",
    "def create_faiss_index(chunks, model):\n",
    "    \"\"\"\n",
    "    Creates a FAISS index from the text chunks' embeddings.\n",
    "    \"\"\"\n",
    "    if not chunks:\n",
    "        print(\"No chunks available to create an index.\")\n",
    "        return None\n",
    "    embeddings = model.encode(chunks, convert_to_tensor=True, show_progress_bar=True)\n",
    "    embeddings = embeddings.cpu().numpy()\n",
    "    faiss.normalize_L2(embeddings)\n",
    "    index = faiss.IndexFlatIP(embeddings.shape[1])\n",
    "    index.add(embeddings)\n",
    "    print(f\"âœ… FAISS index created successfully with {len(chunks)} vectors.\")\n",
    "    return index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4c445798",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to Handle Queries with On-Demand Model Loading \n",
    "def handle_query_with_faiss(query, index, chunks, embedding_model, mode=\"qa\", top_k=3):\n",
    "    \"\"\"\n",
    "    Handles a user query by loading the required model on-demand and\n",
    "    clearing it from memory immediately after use to prevent crashes.\n",
    "    \"\"\"\n",
    "    if index is None:\n",
    "        return \"Error: The document index is not available.\"\n",
    "\n",
    "    query_embedding = embedding_model.encode([query])\n",
    "    faiss.normalize_L2(query_embedding)\n",
    "    _, indices = index.search(query_embedding, top_k)\n",
    "    context = \" \".join([chunks[i] for i in indices[0]])\n",
    "    \n",
    "    result = \"\"\n",
    "\n",
    "    if mode == \"qa\":\n",
    "        print(\"Loading QA model...\")\n",
    "        qa_pipeline = pipeline(\"question-answering\", model=\"distilbert-base-cased-distilled-squad\")\n",
    "        answer = qa_pipeline(question=query, context=context)\n",
    "        result = ' '.join(answer['answer'].split()) # Clean the answer\n",
    "        del qa_pipeline # Delete the model from memory\n",
    "        gc.collect() # Ask Python to collect the garbage\n",
    "        print(\"QA model cleared from memory.\")\n",
    "\n",
    "    elif mode == \"summarize\":\n",
    "        print(\"Loading Summarizer model...\")\n",
    "        summarizer = pipeline(\"summarization\", model=\"t5-small\")\n",
    "        summary = summarizer(context, max_length=100, min_length=25, do_sample=False)\n",
    "        result = summary[0]['summary_text']\n",
    "        del summarizer # Delete the model from memory\n",
    "        gc.collect() # Ask Python to collect the garbage\n",
    "        print(\"Summarizer model cleared from memory.\")\n",
    "\n",
    "    else: # Search mode\n",
    "        result = [chunks[i] for i in indices[0]]\n",
    "        \n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "244b62d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading the embedding model (all-MiniLM-L6-v2)...\n",
      "Embedding model loaded.\n",
      "Successfully loaded and created 5 chunks from 'E:\\Radhika\\radhika-intern\\testpdf.pdf'.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "34310fc61dd5472fa060e9f93c03fd53",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… FAISS index created successfully with 5 vectors.\n",
      "\n",
      "--- Starting Query Session ---\n",
      "\n",
      "--- Testing QA Mode ---\n",
      "\n",
      "Query: Who found the golden key?\n",
      "Loading QA model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QA model cleared from memory.\n",
      "Answer: Sam\n",
      "\n",
      "Query: What is the reward for caring for the garden?\n",
      "Loading QA model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QA model cleared from memory.\n",
      "Answer: rewar ded with happiness and the peacefulness of natur e\n",
      "\n",
      "--- Testing Summarizer Mode ðŸ“ ---\n",
      "Query: Summarize Sam's discovery in the forest.\n",
      "Loading Summarizer model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n",
      "Both `max_new_tokens` (=256) and `max_length`(=100) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summarizer model cleared from memory.\n",
      "Summary: the garden grew more beautiful each day, and Sam felt happier than ever . he decided to explor e deeper into the forest, hoping to find a lock that matched his key .\n",
      "\n",
      "--- Testing Search Mode ðŸ” ---\n",
      "Query: magical garden and its guardian\n",
      "Top Relevant Chunks Found:\n",
      "  [1] key,\n",
      " \n",
      "the\n",
      " \n",
      "door\n",
      " \n",
      "creaked\n",
      " \n",
      "open\n",
      " \n",
      "slowly ,\n",
      " \n",
      "revealing\n",
      " \n",
      "a\n",
      " \n",
      "hidden\n",
      " \n",
      "garden\n",
      " \n",
      "full\n",
      " \n",
      "of\n",
      " \n",
      "color ful\n",
      " \n",
      "ï¬‚owers\n",
      " \n",
      "and\n",
      " \n",
      "sparkling\n",
      " \n",
      "fountains.\n",
      " \n",
      "In\n",
      " \n",
      "the\n",
      " \n",
      "middle\n",
      " \n",
      "of\n",
      " \n",
      "the\n",
      " \n",
      "garden\n",
      " \n",
      "stood\n",
      " \n",
      "a\n",
      " \n",
      "beautiful\n",
      " \n",
      "old\n",
      " \n",
      "bench\n",
      " \n",
      "wher e\n",
      " \n",
      "an\n",
      " \n",
      "elderly\n",
      " \n",
      "woman\n",
      " \n",
      "sat,\n",
      " \n",
      "smiling\n",
      " \n",
      "warmly .\n",
      " \n",
      "She\n",
      " \n",
      "introduced\n",
      " \n",
      "herself\n",
      " \n",
      "as\n",
      " \n",
      "the\n",
      " \n",
      "guar dian\n",
      " \n",
      "of\n",
      " \n",
      "the\n",
      " \n",
      "secr et\n",
      " \n",
      "garden.\n",
      " \n",
      "The\n",
      " \n",
      "woman\n",
      " \n",
      "explained\n",
      " \n",
      "that\n",
      " \n",
      "the\n",
      " \n",
      "garden\n",
      " \n",
      "was\n",
      " \n",
      "magical\n",
      " \n",
      "and\n",
      " \n",
      "only\n",
      " \n",
      "appear ed\n",
      " \n",
      "to\n",
      " \n",
      "kind\n",
      " \n",
      "and\n",
      " \n",
      "curious\n",
      " \n",
      "hear ts.\n",
      "  [2] appear ed\n",
      " \n",
      "to\n",
      " \n",
      "kind\n",
      " \n",
      "and\n",
      " \n",
      "curious\n",
      " \n",
      "hear ts\n",
      " \n",
      "like\n",
      " \n",
      "Sam â€™s.\n",
      " \n",
      "She\n",
      " \n",
      "told\n",
      " \n",
      "him\n",
      " \n",
      "that\n",
      " \n",
      "anyone\n",
      " \n",
      "who\n",
      " \n",
      "cared\n",
      " \n",
      "for\n",
      " \n",
      "the\n",
      " \n",
      "garden\n",
      " \n",
      "would\n",
      " \n",
      "be\n",
      " \n",
      "rewar ded\n",
      " \n",
      "with\n",
      " \n",
      "happiness\n",
      " \n",
      "and\n",
      " \n",
      "the\n",
      " \n",
      "peacefulness\n",
      " \n",
      "of\n",
      " \n",
      "natur e.\n",
      " \n",
      "From\n",
      " \n",
      "that\n",
      " \n",
      "day\n",
      " \n",
      "on,\n",
      " \n",
      "Sam\n",
      " \n",
      "visited\n",
      " \n",
      "the\n",
      " \n",
      "garden\n",
      " \n",
      "often.\n",
      " \n",
      "He\n",
      " \n",
      "water ed\n",
      " \n",
      "the\n",
      " \n",
      "plants,\n",
      " \n",
      "fed\n",
      " \n",
      "the\n",
      " \n",
      "birds,\n",
      " \n",
      "and\n",
      " \n",
      "cleaned\n",
      " \n",
      "the\n",
      " \n",
      "paths.\n",
      " \n",
      "The\n",
      " \n",
      "garden\n",
      " \n",
      "grew\n",
      " \n",
      "more\n",
      " \n",
      "beautiful\n",
      " \n",
      "each\n",
      " \n",
      "day,\n",
      " \n",
      "and\n",
      " \n",
      "Sam\n",
      " \n",
      "felt\n",
      " \n",
      "happier\n",
      " \n",
      "than\n",
      " \n",
      "ever.\n",
      " \n",
      "He\n",
      " \n",
      "learned\n",
      " \n",
      "that.\n",
      "  [3] Once\n",
      " \n",
      "upon\n",
      " \n",
      "a\n",
      " \n",
      "time\n",
      " \n",
      "in\n",
      " \n",
      "a\n",
      " \n",
      "small\n",
      " \n",
      "village,\n",
      " \n",
      "there\n",
      " \n",
      "was\n",
      " \n",
      "a\n",
      " \n",
      "boy\n",
      " \n",
      "named\n",
      " \n",
      "Sam\n",
      " \n",
      "who\n",
      " \n",
      "loved\n",
      " \n",
      "to\n",
      " \n",
      "explor e.\n",
      " \n",
      "Every\n",
      " \n",
      "day\n",
      " \n",
      "after\n",
      " \n",
      "school,\n",
      " \n",
      "Sam\n",
      " \n",
      "would\n",
      " \n",
      "go\n",
      " \n",
      "to\n",
      " \n",
      "the\n",
      " \n",
      "nearb y\n",
      " \n",
      "forest\n",
      " \n",
      "to\n",
      " \n",
      "disco ver\n",
      " \n",
      "new\n",
      " \n",
      "things.\n",
      " \n",
      "One\n",
      " \n",
      "afternoon,\n",
      " \n",
      "while\n",
      " \n",
      "walking\n",
      " \n",
      "along\n",
      " \n",
      "a\n",
      " \n",
      "narrow\n",
      " \n",
      "path,\n",
      " \n",
      "he\n",
      " \n",
      "found\n",
      " \n",
      "a\n",
      " \n",
      "shiny ,\n",
      " \n",
      "golden\n",
      " \n",
      "key\n",
      " \n",
      "half-buried\n",
      " \n",
      "under\n",
      " \n",
      "some\n",
      " \n",
      "leaves.\n",
      " \n",
      "Curious,\n",
      " \n",
      "he\n",
      " \n",
      "picked\n",
      " \n",
      "it\n",
      " \n",
      "up\n",
      " \n",
      "and\n",
      " \n",
      "wonder ed\n",
      " \n",
      "what\n",
      " \n",
      "it\n",
      " \n",
      "might\n",
      " \n",
      "open.\n",
      " \n",
      "Sam\n",
      " \n",
      "decided\n",
      " \n",
      "to\n",
      " \n",
      "explor e.\n"
     ]
    }
   ],
   "source": [
    "# Main Execution Block\n",
    "\n",
    "# Make sure you have all necessary imports\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from transformers import pipeline\n",
    "import faiss\n",
    "import gc\n",
    "# You will also need your custom 'load_and_chunk_text' and 'create_faiss_index' functions defined elsewhere\n",
    "\n",
    "# 1. SET YOUR FILE PATH\n",
    "# The 'r' is important for Windows paths.\n",
    "FILE_PATH = r\"E:\\Radhika\\radhika-intern\\testpdf.pdf\"\n",
    "\n",
    "# 2. LOAD THE EMBEDDING MODEL\n",
    "print(\"Loading the embedding model (all-MiniLM-L6-v2)...\")\n",
    "embedding_model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "print(\"Embedding model loaded.\")\n",
    "\n",
    "# 3. PROCESS YOUR DOCUMENT\n",
    "# Assuming your custom functions are available\n",
    "text_chunks = load_and_chunk_text(FILE_PATH) \n",
    "faiss_index = create_faiss_index(text_chunks, embedding_model)\n",
    "\n",
    "# 4. TEST THE QA MODEL (Original Queries)\n",
    "if faiss_index:\n",
    "    print(\"\\n--- Starting Query Session ---\")\n",
    "    \n",
    "    # QA Mode\n",
    "    print(\"\\n--- Testing QA Mode ---\")\n",
    "    query1 = \"Who found the golden key?\"\n",
    "    print(f\"\\nQuery: {query1}\")\n",
    "    answer1 = handle_query_with_faiss(query1, faiss_index, text_chunks, embedding_model, mode=\"qa\")\n",
    "    print(f\"Answer: {answer1}\")\n",
    "\n",
    "    query2 = \"What is the reward for caring for the garden?\"\n",
    "    print(f\"\\nQuery: {query2}\")\n",
    "    answer2 = handle_query_with_faiss(query2, faiss_index, text_chunks, embedding_model, mode=\"qa\")\n",
    "    print(f\"Answer: {answer2}\")\n",
    "\n",
    "    # --- Test Summarizer Mode ---\n",
    "    print(\"\\n--- Testing Summarizer Mode ðŸ“ ---\")\n",
    "    summarize_query = \"Summarize Sam's discovery in the forest.\"\n",
    "    print(f\"Query: {summarize_query}\")\n",
    "    summary_answer = handle_query_with_faiss(summarize_query, faiss_index, text_chunks, embedding_model, mode=\"summarize\")\n",
    "    print(f\"Summary: {summary_answer}\")\n",
    "\n",
    "    # --- Test Search Mode ---\n",
    "    print(\"\\n--- Testing Search Mode ðŸ” ---\")\n",
    "    search_query = \"magical garden and its guardian\"\n",
    "    print(f\"Query: {search_query}\")\n",
    "    search_results = handle_query_with_faiss(search_query, faiss_index, text_chunks, embedding_model, mode=\"search\")\n",
    "    \n",
    "    print(\"Top Relevant Chunks Found:\")\n",
    "    if search_results:\n",
    "        for i, chunk in enumerate(search_results, 1):\n",
    "            print(f\"  [{i}] {chunk}.\")\n",
    "    else:\n",
    "        print(\"No relevant chunks found.\")\n",
    "\n",
    "else:\n",
    "    print(\"Failed to create the FAISS index. Cannot proceed with queries.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
